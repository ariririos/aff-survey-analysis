Kinds of questions to answer:
[x] demographics (if res assoc exists, count) => who answered?
    [x] implementation
    [x] schema
[ ] subdemographics (if res assoc is x, count) => what kinds of students and grads answered? what were the averages of students and parents answering? e.g. mode of 2021 currstu answering, 2017 grads answering, average of 2022.3 class year, median of 2021 class year
    [x] implementation
    [ ] schema
[ ] percentages of types of responses for each question (37% of currstu agreed with statement)
    [ ] implementation
    [ ] schema
    [!] do I want this in here? maybe cause it would all be in one analysis but it would also get very very long
[ ] how often was there a non-null answer to a "what do you need help with" question => "37% of currstu answered this question"
    [x] implementation
    [ ] schema
[ ] mean and median responses to Likerts (average response to this question was 3.4 (neutral with a skew towards disagree), median was 3)
    [x] implementation
    [ ] schema
[ ] mode responses to Likerts
    [x] implementation
    [ ] schema
[ ] additional intra-question stats (stddev, variation)
[ ] additional cross-question stats (??? like d-test and t-test shit)
[ ] stats for checkbox questions (37% of students wanted more help in math, 34% of students wanted more help in social studies)
    [ ] answers by choice
        [!] same question as % per question -- too long?
    [x] mode choice
[ ] variations in how a question was answered across subgroups (37% of parents answered this question agree, 47% of currstu agreed;)
    [ ] this is the inverse of how I'm doing this, so maybe do crosschecks after the first two categories instead of mixing them in -- otherwise you'll have repetition
    [ ] link to cross-tabulation at bottom in question
    [ ] see note on aggResByQuestion structure
    [ ] implementation
[ ] percentages of answering a question a certain way if you answered a different question a certain way (37% of currstu who agreed with Q41 also agreed with this question)
    [ ] can include in question, link to the original and link to the cross-checked question from the original
    [ ] for cross-checking, there's two directions: list as alternate interpretation (25% (of 40) of students who agreed with Q41 agreed with Q42; 33% (or 30) of students who agreed with Q42 agreed with Q41)
    [ ] you can also have multi-cross checks (70% of agree/neutral also answered agree/neutral)
        [x] implementation
        [ ] schema decisions
        [ ] schema
    [ ] you can also have multiple cross checks per question
        [x] implementation
        [ ] schema decisions
        [ ] schema
    [x] implementation
    [ ] schema decisions
    [ ] schema
[ ] within-question cross-checking:
    [ ] i.e. did students who couldn't find help with math also say they couldn't find help with science? => maybe display as "students who answered math answered {} 70% of the time"
    [ ] could do as part of same cross-check alg -- just use a special symbol for question (e.g. not defining the property, 'same', this)
    [x] implementation
    [ ] schema decisions
    [ ] schema
[ ] overall: questions that had significant skipping from certain groups and across groups (>x%); all text responses outputted for a question (mark in stats schema to just spit out the data, don't do any analysis); % of questions answered per subgroup

[ ] for new questions, add to:
    - globalSymbols: questionTypes and questionShortTitles
    - dataStructureSchema
    - questionStatsSchema
[ ] skipped: [34, 35, 36, 37, 39, 40, 44, 56, 57] TEXT,


BIG THINK:
[ ] which questions do I want to cross-check?
    [ ] couldn't find SAT help 1=> too basic or advanced? 1=> help unavailable at times I wanted?

[ ] to mix with incompletes: have a similar data structure that just nest checks for answers to questions and short circuits to removing the response if any aren't answered
[ ] aggResByQuestion as currently set up removes the assoc info from the answers -- this is fine for now, but when looking at differences in answers between associations that answered the same question, it won't have enough data to differentiate
    [ ] I might be able to just disregard the (agg) that's passed in and look at resByAssoc myself and construct a new aggResByQuestionByAssoc

/**
 * Notes on data structure:
 * there are only single/multiple choice, textbox, and dropdown questions in this survey
 */

 /**
  * Todo:
  * - deal with incomplete (maybe have some schema of what they need to have answered to be considered) + check for duplicates (in completed and incomplete)
**/